개념적으로, 가상 메모리는 디스크에 저장된 N개의 연속된 바이트 단위 셀로 구성된 배열로 볼 수 있습니다.
각 바이트는 고유한 가상 주소를 가지며, 이는 인덱스로 이용됩니다.

또한 디스크의 데이터는 가상 페이지라는 고정된 전송 단위를 가집니다. (캐시에서의 블락과 상응하는 개념)
물리 메모리도동일하게 물리 페이지라는 개념을 가지고, 이는 페이지 프레임이라고도 부릅니다.

#### 가상 페이지의 세가지 상태
1. Unallocated
2. Cached
3. Uncached

***

# 01-DRAM Cache Organization
DRAM은 SRAM보다 약 10배 느리지만, 디스크는 DRAM보다 약 10만배 느립니다.
따라서 DRAM 미스 비용은 매우 큽니다.
#### 캐시 적중률을 높이기 위한 정책
1. 가상 페이지의 크기를 크게 설계
2. 완전 연관형(fully-associative) (완전연관형이 뭐야??)
3. 복잡하고 정교한 페이지 교체 알고리즘
4. Write-Back 정책

***

# 02-Page Tables
캐싱을 추적하기 위해서 페이지 테이블을 사용합니다. 각 가상 페이지(VP)마다 하나의 페이지 엔트리 테이블(PTE)을 가집니다. 각 PTE는 유효 비트와 주소 필드를 가집니다.

***

# 03-Page Hits
CPU가 DRAM에 캐싱된 VP2 내 데이터를 읽으려고 할 때, 주소 변환 하드웨어는 가상 주소를 PTE 인덱스로 사용해 PTE2를 찾습니다. valid 비트가 1이므로, 해당 가상 페이지가 캐싱되어 있음을 알 수 있습니다. 따라서 PTE에 저장된 물리 페이지 주소(PP1)를 이용해 실제 물리 주소를 구성합니다. 이것이 페이지 히트(Page Hit)입니다.

***

# 04-Page Faults
만약 CPU가 DRAM에 존재하지 않는 가상 페이지(VP3)를 참조하면, 주소 변환 하드웨어는 valid 비트가 0임을 확인하고 페이지 폴트(page fault)를 발생시킵니다. 커널은 페이지 폴트 예외 처리기를 호출하여, 교체할 희생 페이지(victim page)를 선택하고 디스크에서 VP3 데이터를 읽어와 PP3에 저장합니다. 그리고 페이지 테이블 갱신을 완료 후 폴트가 발생한 명령을 재시작하면 정상적으로 메모리에서 데이터를 읽습니다. 이러한 디스크-메모리 간의 전송을 스와핑(swapping)또는 페이징(paging)이라고 합니다.

***

# 05-Allocating Pages
운영체제가 새로운 가상 페이지를 생성할 때(예: malloc 호출 결과), 새로운 디스크 공간을 확보하고 페이지 테이블을 업데이트합니다. 즉, PTE를 디스크의 새 페이지 위치로 설정합니다.

***

# 06-Locality to the Rescue Again
프로그램이 실행 중 참조하는 페이지의 전체 수는 물리 메모리보다 훨씬 많더라도, 어느 한 시점에는 그중 일부 활성 페이지(active pages)만 사용됩니다. 이 집합을 워킹 세트(working set) 또는 거주 세트(resident set)라고 부릅니다. 워킹 세트가 메모리에 올라오면 이후 접근은 대부분 히트(hit)가 되며, 추가적인 디스크 접근 없이 빠르게 수행됩니다. 단, 프로그램의 워킹 세트가 물리 메모리보다 커지면 스래싱(thrashing)이 발생합니다. 이는 페이지 교체가 너무 자주 일어나서 시스템이 계속 디스크 입출력만 수행하는 상태를 말합니다.

#### 프로세스별 독립된 주소 공간
운영체제는 각 프로세스마다 별도의 페이지 테이블을 유지합니다.
이 덕분에 각 프로세스는 서로 독립된 가상 주소 공간을 가집니다.
그러나 공통 데이터(예: 공유 라이브러리)는 공유 페이지(shared page)로 설정되어 서로 다른 프로세스가 같은 물리 메모리를 참조할 수도 있습니다.