지금까지 우리는 **단일 프로세서(uniprocessor)** 시스템에서 동시 실행되는 스레드(concurrent threads)를 가정했다.
하지만 현대의 대부분의 컴퓨터는 **멀티코어 프로세서(multicore processor)** 를 가지고 있다.

멀티코어 시스템에서는 운영체제 커널이 여러 스레드를 서로 다른 코어에서 동시에 실행시킬 수 있다.
따라서 **병행 프로그램(concurrent program)** 은 단일 코어에서 순차적으로 실행될 때보다
멀티코어에서 병렬(parallel)로 실행될 때 훨씬 빠르게 동작한다.

이러한 병렬성(parallelism)은

* 웹 서버,
* 데이터베이스 서버,
* 대규모 과학 계산 코드 등

성능이 중요한 애플리케이션에서 매우 중요하다.
심지어 웹 브라우저나 문서 편집기 같은 일반 프로그램에서도 점점 더 많이 사용된다.

### Figure 12.30 — 순차적, 병행적, 병렬적 프로그램의 관계

![[Screenshot 2025-11-07 at 15.37.29.png]]

모든 프로그램은 두 가지로 나눌 수 있다:

* ==**순차적 프로그램 (Sequential program)**==: 하나의 논리적 흐름으로 작성됨.
* ==**병행 프로그램 (Concurrent program)**==: 여러 개의 동시 흐름으로 작성됨.

그중에서도 ==**병렬 프로그램 (Parallel program)**== 은 병행 프로그램 중에서도
**여러 개의 프로세서에서 동시에 실행되는 경우**를 말한다.
따라서 병렬 프로그램은 병행 프로그램의 **부분집합(subset)** 이다.

### 병렬 합 계산 예제 (Parallel Summation)

간단한 예로, 정수 0부터 ( n-1 )까지의 합을 구한다고 하자.
이 문제를 병렬로 해결하기 위해, 전체 구간을 ( t )개의 구간으로 나누고,
각 스레드가 자기 구간의 합을 계산하도록 할 수 있다.

## 첫 번째 방법: 뮤텍스로 보호된 전역 합 (psum-mutex)

가장 단순한 방법은 **전역 변수 gsum** 하나를 두고,
모든 스레드가 계산한 값을 이 변수에 더해가는 것이다.
단, 동시에 접근하면 데이터가 깨지므로 **뮤텍스(mutex)** 로 보호한다.

```c
/* 전역 변수 */
long gsum = 0;
sem_t mutex;

void *sum_mutex(void *vargp) {
  long myid = *((long *)vargp);
  long start = myid * nelems_per_thread;
  long end = start + nelems_per_thread;
  for (long i = start; i < end; i++) {
    P(&mutex);
    gsum += i;
    V(&mutex);
  }
  return NULL;
}
```

* 각 스레드는 자신만의 ID(`myid`)를 받아서 합칠 구간을 계산한다.
* 전역 합(`gsum`)을 갱신할 때는 세마포어 P/V로 잠금(lock/unlock).

### 성능 결과

| 버전         | 1스레드 | 2스레드 | 4스레드 | 8스레드 | 16스레드 |
| ---------- | ---- | ---- | ---- | ---- | ----- |
| psum-mutex | 68   | 432  | 719  | 552  | 599   |

👉 결과: **스레드가 많아질수록 오히려 느려진다!**

#### 이유:

* ==`P()`와 `V()` 같은 **동기화 연산(synchronization)** 은 매우 비싸다.==
* 한 번의 단순한 메모리 업데이트보다 훨씬 큰 비용이 든다.
* 따라서 병렬 프로그램에서는 ==**동기화를 최소화**==해야 한다.

> **핵심 교훈:**
> “동기화 오버헤드는 비싸다. 피할 수 없다면, 가능한 많은 연산으로 그 비용을 상쇄(amortize)하라.”

## 두 번째 방법: 각 스레드가 자기 배열 원소를 사용 (psum-array)

동기화 비용을 없애기 위해,
각 스레드가 **자기만의 배열 원소**에 합을 저장하도록 바꾼다.

```c
long psum[MAXTHREADS];

void *sum_array(void *vargp) {
  long myid = *((long *)vargp);
  long start = myid * nelems_per_thread;
  long end = start + nelems_per_thread;
  for (long i = start; i < end; i++) {
    psum[myid] += i;
  }
  return NULL;
}
```

* 각 스레드는 `psum[myid]`에 자기 구간의 합만 더함 → 충돌 없음.
* 스레드가 종료된 후 메인 스레드가 모든 `psum` 값을 더해서 최종 결과 계산.

### 성능 결과

| 버전         | 1    | 2     | 4     | 8     | 16    |
| ---------- | ---- | ----- | ----- | ----- | ----- |
| psum-mutex | 68.0 | 432.0 | 719.0 | 552.0 | 599.0 |
| psum-array | 7.26 | 3.64  | 1.91  | 1.85  | 1.84  |

👉 **엄청난 성능 향상!**
==스레드 수가 많아져도 거의 일정한 속도를 유지.==

## 세 번째 방법: 지역 변수 사용 (psum-local)

Chapter 5에서 배운 것처럼, **지역 변수(local variable)** 는
전역 메모리보다 훨씬 빠르게 접근할 수 있다.

```c
void *sum_local(void *vargp) {
  long myid = *((long *)vargp);
  long start = myid * nelems_per_thread;
  long end = start + nelems_per_thread;
  long sum = 0;
  for (long i = start; i < end; i++) {
    sum += i;
  }
  psum[myid] = sum;
  return NULL;
}
```

### 성능 비교

| 버전         | 1    | 2     | 4     | 8     | 16    |
| ---------- | ---- | ----- | ----- | ----- | ----- |
| psum-mutex | 68.0 | 432.0 | 719.0 | 552.0 | 599.0 |
| psum-array | 7.26 | 3.64  | 1.91  | 1.85  | 1.84  |
| psum-local | 1.06 | 0.54  | 0.28  | 0.29  | 0.30  |

👉 지역 변수 버전은 전역 메모리 접근을 없애 ==**또 한 단계의 성능 향상**==을 달성했다.

## Figure 12.35 — psum-local의 실행 시간

![[Screenshot 2025-11-07 at 15.44.25.png]]

그래프를 보면 스레드 수가 4개(코어 수와 같을 때)까지는 선형적으로 실행 시간이 감소하지만, 그 이상에서는 오히려 증가하기 시작한다.

> 이유: 4개의 코어가 모두 사용된 이후에는 ==**문맥 전환(context switching)**== 오버헤드가 발생하기 때문.

## 병렬 프로그램의 성능 분석

병렬 프로그램의 효율성을 수학적으로 분석할 수 있다.

### **Speedup (속도 향상 비율)**

![[Screenshot 2025-11-07 at 15.46.21.png]]
* (T_1): 한 개 코어로 실행한 시간
* (T_p): p개의 코어로 실행한 시간

### **Efficiency (병렬 효율성)**

![[Screenshot 2025-11-07 at 15.46.44.png]]

* 효율성은 0~100% 범위로 나타냄
* 동기화/통신에 낭비되는 시간이 적을수록 효율이 높음

### Figure 12.36 — psum-local의 속도 향상과 효율

![[Screenshot 2025-11-07 at 15.45.56.png]]

효율이 90% 이상이면 매우 우수한 병렬화다.
하지만 이 예제는 매우 단순한 문제이기 때문에 이렇게 높게 나온 것이다.
==실제 복잡한 병렬 프로그램에서는 훨씬 어렵다.==

## Strong Scaling vs Weak Scaling

* **Strong Scaling (강 스케일링)**
  → 전체 작업량을 고정한 채, 프로세서 수를 늘려 **처리 시간을 줄이는 것**.

* **Weak Scaling (약 스케일링)**
  → 프로세서 수를 늘리면서 각 프로세서가 처리하는 작업량도 함께 늘려 **전체 처리량을 일정하게 유지하는 것**.

> 약 스케일링은 “큰 기계를 써서 더 많은 일을 한다”는 우리의 실제 목표를 더 잘 반영하는 척도다.
> ==(차이점은 작업량이 일정한지 늘어나는지 차이밖에 없는건가?)==

### 언제 어떤 스케일링을 쓰나?

* **Weak scaling**: 과학 계산처럼 문제 크기를 쉽게 키울 수 있을 때 적합
* **Strong scaling**: 실시간 신호 처리처럼 문제 크기가 고정되어 있을 때 적합

> 예를 들어 센서에서 실시간으로 들어오는 신호를 처리하는 프로그램은 센서의 개수가 물리적으로 고정되어 있으므로 **strong scaling** 이 더 적절하다.

